---
title: "Getting started"
author: ""
date: ""
output: html_document
---

Let's get starting using `sdeTMB`!

We shall assume that you have some time series `data`, and a stochastic differential equation model which you believe can be used to model that data (or some latent variable that can be linked to your data). 

Here we consider the Ornstein-Uhlenbeck process
$$ 
\mathrm{d}X_{t} = \theta (\mu - X_{t}) \, \mathrm{d}t \, + \sigma_{X} \, \mathrm{d}B_{t} 
$$
where $\theta$, $\mu$ and $\sigma_x$ are (fixed effects) parameters in the model to be estimated. 

We assume that we have direct observations of the state $X_{t}$ i.e. the observation equation is
$$
Y_{t_{k}} = X_{t_{k}} + \varepsilon_{t_{k}} \qquad \varepsilon_{t_{k}} \sim \mathcal{N}(0,\sigma_{Y}^{2} \cdot U_{t_{k}})
$$
and the residuals are normally distributed with variance $\sigma_{Y}^{2} \cdot U_{t}$, where $\sigma_{Y}$ is a fixed effect (parameter) which should also be estimated, and $U_{t}$ is an input. The input is added purely for the sake of this example. It could for instance be a vector 
$$
U_{t_{i}} = \left\{ 1,2,1,2,1,2,\cdots \right\}
$$
so that some observations have a larger variance than others, i.e. we believe them to be a less accurate measurement of $Y$.

# Initialising

---

We initialise a `sdeTMB` model object using
```{r}
library(sdeTMB)
obj = sdeTMB$new()
```

We can print the object to see what kind of model it contains
```{r}
print(obj)
```

We see that the model is called `sde_model` (default), and there are no states, diffusions, observations, inputs or parameters currently registered. The name is used to name the `C++` file that will be created locally, and to later recognize the compiled model object.

# Add system equations

---

We can begin by adding the desired stochastic differential equation to the object.
```{r}
obj$add_systems(dX ~ theta * (mu - X) * dt + sigma_x * dw)
```
We note that the drift term ends with `*dt` and diffusions are specified by `dw` or `dw#` where `#` can be any sequence of numbers.

# Add observation equations

---

We must also add the observation equation.
```{r}
obj$add_observations(Y ~ X)
```

The observations associated with `Y` in the `data` should also be named `Y`. 

# Add observation variances

---

For every observation variable we must also specify the variance of the normally distributed residuals for that observation equation
```{r}
obj$add_observation_variances(Y ~ sigma_y^2*U)
```
The variable name on the left-hand side of the formula must match a name previously defined via `add_observations`, and the variance is associated with that observation equation.

Let's inspect the model object again
```{r}
print(obj)
```
So now we have specified one state $X$ and an observation $Y$. The diffusions count the number of $\mathrm{d}\omega_{i}$ terms. A single equation can have multiple diffusion terms i.e. `sigma_1 * dw1 + sigma_2*dw2`). We also note that there are no inputs and no parameter specified yet.

# Add inputs

---

We tell the model which variable names are inputs via
```{r}
obj$add_inputs(U)
```
The input values should be provided in the `data`, with the same name, similar to the observations.


# Add parameters

---

We must also specify the (fixed effects) parameters, together with their initial value and lower/upper bound, for the optimization.
```{r}
obj$add_parameters(
  theta   = c(initial = 5,    lower = 0,    upper = 20),
  mu      = c(initial = 0,    lower = -10,  upper = 10),
  sigma_x = c(initial = 1e-1, lower = 1e-5, upper = 5),
  sigma_y = c(initial = 1e-1, lower = 1e-5, upper = 5)
)
```

We can fix a parameter value (so the parameter becomes a constant) by supplying just a single value. It is usually difficult to identify both of the noise parameters $\left(\sigma_{X},\sigma_{Y}\right)$ in practice, so lets assume that we want to fix $\sigma_{Y}$. This is done via
```{r}
obj$add_parameters(
  sigma_y  = 1e-1
)
```

Let's inspect the model object again, and see that inputs and parameters (both non-fixed and fixed) have been registered.
```{r}
print(obj)
```

# Set initial state and covariance

---

The last thing to do before we can perform estimation is to set the initial value of the state(s) and its associated (co)variance. These two inputs are adequate since we assume a normally distributed state. The choice of value should reflect ones belief in the initial state, but it is most often a ballpark figure.
```{r}
obj$set_initial_state(list(mean=3, cov=1e-1*diag(1)))
```
Note that we use `diag` to construct a 1x1 matrix for the covariance, as required by the method.


# Fit model parameters to data

---

We are now ready to perform state filtration and parameter estimation. We first construct some fake data by simulating paths of the Ornstein-Uhlenbeck process using the [Euler-Maruyama scheme](https://en.wikipedia.org/wiki/Eulerâ€“Maruyama_method).
```{r, include=TRUE}
# Choosing parameters
set.seed(10)
theta=10; mu=1; sigma_x=1; sigma_y=1e-1
 
# Creating simulation path
dt.sim = 1e-3
t.sim = seq(0,1,by=dt.sim)
dw = rnorm(length(t.sim)-1,sd=sqrt(dt.sim))
x = 3
for(i in 1:(length(t.sim)-1)) {
  x[i+1] = x[i] + theta*(mu-x[i])*dt.sim + sigma_x*dw[i]
}

# Extract observations from simulation and add noise
dt.obs = 1e-2
t.obs = seq(0,1,by=dt.obs)
y = x[t.sim %in% t.obs] + sigma_y * rnorm(length(t.obs))

# Create data.frame
data = data.frame(
  t = t.obs,
  Y = y,
  U = c(rep(c(1,2),times=round(length(y)/2)),1)
)
```

The data must contain a time column named `t` and columns for each of the specified inputs and observations.

We pass the `data` to the `estimate` method. The method will build and compile a generated `C++` function for the negative log-likelihood, check if the supplied data contains all necessary variables, construct the objective function (the computational tree must be build for automatic differentiation) and then start the optimization. 

The output generated during the optimization is the objective (negativ log-likelihood) value and parameter values at the current step. The optimizer used in the package is `stats::nlminb`. This optimizer is great because of its robustness and ability to use the objective function hessian unlike e.g. 'stats::optim'

```{r}
fit = obj$estimate(data)
```

# **Important Note for Model Changes**

---

If you change the model at a later stage but retain the same model name, then you need to recompile the `C++` objective function. You can do this like so:
```{r, eval=FALSE}
obj$estimate(data, compile=TRUE)
```

If you receive error messages when calling `estimate` regarding variables that are not in your specified model, it is likely because you forgot to recompile.

# Parameter estimates

---

Let's inspect results from the estimation.

We can print the `fit` object to see a standard coefficient matrix for the parameter estimates.
```{r}
print(fit)
```
We can see the parameter estimate and the associated standard error together with the t-test statistic and P-value associated with the standard null-hypothesis 
$$
H_{0}: p = 0 \\
H_{1}: p \neq 0
$$
Note that the true parameter values were set during the simulation step as $\theta = 10$, $\mu=1$ and $\sigma_{X} = 1$.

The parameter values, standard deviations and covariance matrix can be extracted via:

The estimated (fixed) parameters:
```{r}
fit$par.fixed
```

The standard deviations of the (fixed) parameters:
```{r}
fit$sd.fixed
```

The covariance of the (fixed) parameters:
```{r}
fit$cov.fixed
```

# State estimates

---

We can also plot prior and posterior state estimates The prior state estimate is the resulting estimate purely from integrating the mean and covariance of the SDE system forward in time, while the posterior state estimation is obtained from updating the prior estimate with the information contained in the observation (using Bayes' rule).

```{r}
library(ggplot2)
library(patchwork)
```


```{r, include=TRUE}
# ggplot2 theme
mytheme =
  theme_minimal() + 
  theme(
    text             = element_text("Avenir Next Condensed",size=15),
    legend.text      = element_text(size=15),
    axis.text        = element_text(size=15),
    strip.text       = element_text(face="bold",size=15),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    legend.box       = "vertical",
    legend.position  = "top",
    plot.title       = element_text(hjust=0.5)
  )
```


```{r}
t         = fit$states$mean$posterior$t
xprior    = fit$states$mean$prior$X
xpost     = fit$states$mean$posterior$X
xpost_sd  = fit$states$sd$posterior$X

ggplot() +
  geom_line(aes(x=t,y=xpost,color="State Estimates (Posterior)"),lwd=1) +
  geom_line(aes(x=t,y=xprior,color="State Estimates (Prior)"),lwd=1) +
  geom_ribbon(aes(x=t,ymin=xpost-2*xpost_sd,ymax=xpost+2*xpost_sd),fill="grey",alpha=0.5) +
  geom_point(aes(x=data$t,data$Y,color="Observations")) +
  guides(color=guide_legend(override.aes=list(shape=c(16,NA,NA),size=c(2,NA,NA),linetype=c(NA,1,1),lwd=c(NA,1,1)))) +
  labs(x = "Time", y = "", color="") +
  mytheme
```

# Residual analysis

---

We can display a standard residual analysis for the observations by calling `plot` on the `fit` object, which invokes the `S3` `plot.sdeTMB.fit` method of `plot`. This includes a quantile-quantile plot, histogram, auto-correlations and cumulative periodogram.

```{r, fig.height=7}
plot(fit)
```
The residuals (both standard and normalized) can be extracted as well, together with their standard deviation and covariance matrix via `fit$residuals`

# **Extra:** Adding algebraic equations

---

For the sake of clarity it can sometimes be easier to specify simple variables in the equations in place of some other (perhaps larger) expression. We can redefine a variable name by providing an algebraic relation.

Let's say that we wish only to consider positive values of the parameter $\theta$, then it is appropriate to estimate in the log-domain (since the domain of the logarithm is the positive real axis). We use $\theta = \exp\left(\log\theta\right)$ and introduce the parameter `logtheta` to replace `theta`. This is obviously just names, and you might as well have written `exp(theta)` directly when specifying the system equations, but calling the parameter `logtheta` reminds one that we are really interested in the exponential of the parameter.

We specify the algebraic relation like so:
```{r}
obj$add_algebraics(theta ~ exp(logtheta))
```

The parameter settings for `theta` are not automatically transformed into `logtheta`, so they must be redefined:
```{r}
obj$add_parameters(logtheta = log(c(initial=5, lower=0, upper=20)))
```


